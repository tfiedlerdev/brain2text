program: run.py
method: bayes
name: timit_w2v_suc_ctc_lr+ctc_hidden_size+gamma+gru_class_hidden_size
entity: machine-learning-hpi
project: brain2text
run_cap: 100
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - ${args}
  - --use_wandb=true
  - --suc_dropout=0.4002714380900173
  - --suc_hidden_sizes=[4096,1024,512,256]
  - --weight_decay=4.412757798785471e-05
  - --early_stopping_patience=4
  - --experiment_type=timit_w2v_suc_ctc
  - --return_best_model=true
  - --epochs=40
  - --batch_size=32
  - --scheduler_step_size=5
  - --optimizer_epsilon=0.1
  - --gradient_clipping=1
  - --suc_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/timit_w2v_suc/2024-07-18_12#09#56/suc.pt
  - --ctc_num_gru_layers=1
  - --scheduler_gamma=0.5
metric:
  name: val_ctc_loss
  goal: minimize
parameters:
  learning_rate:
    min: 0.0001
    max: 0.1
  ctc_gru_hidden_size:
    values: [20, 30, 40, 50, 60]