# --experiment_type=b2p2t_gru+w2v --encoder_gru_hidden_size=256 --encoder_fc_hidden_sizes=[] --encoder_num_gru_layers=2 --epochs=100 --batch_size=32 --learning_rate=0.00001 --encoder_dropout=0.4 --from_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2p2t_gru+w2v/2024-08-01_15#38#46/model.pt --return_best_model=true --early_stopping_patience=4
program: run.py
method: bayes
name: b2p2t_gru+w2v__fightoverfit
entity: machine-learning-hpi
project: brain2text
run_cap: 100
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - ${args}
  - --use_wandb=true
  - --experiment_type=b2p2t_gru+w2v
  - --loss_function=ctc
  - --early_stopping_patience=4
  - --epochs=100
  - --batch_size=32
  - --encoder_gru_hidden_size=256
  - --encoder_fc_hidden_sizes=[]
  - --encoder_num_gru_layers=2
  - --learning_rate=0.0001
  - --return_best_model=true
metric:
  name: test_ctc_loss
  goal: minimize
parameters:
  encoder_dropout:
    min: 0.0
    max: 0.5
  encoder_learnable_inital_state:
    values: ["true", "false"]
  constantOffsetSD:
    min: 0.0
    max: 0.3
  whiteNoiseSD:
    min: 0.0
    max: 1.0
  weight_decay: 
    min: 0.0
    max: 0.001
  gaussian_smooth_width:
    min: 0.0
    max: 2.0
