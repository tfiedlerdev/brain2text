{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: run.py",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false
        },
        {
            "name": "run.py audio_wav2vec",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--experiment_type=audio_wav2vec"
            ]
        },
        {
            "name": "run.py b2t_audio_wav2vec",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_audio_wav2vec"
            ]
        },
        {
            "name": "run.py b2t_custom_encoder",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_wav2vec_custom_encoder",
                "--batch_size=8",
                "--epochs=1",
                "--learning_rate=0.001",
                "--unfreeze_strategy=all",
                "--sample_rate=50",
                "--tokenizer_checkpoint=facebook/wav2vec2-base-100h",
                "--wav2vec_checkpoint=facebook/wav2vec2-xls-r-300m",
                "--mode=pretraining",
                "--preprocessing=seperate_zscoring_2channels",
                "--tokenizer_checkpoint=facebook/wav2vec2-base-100h"
            ]
        },
        {
            "name": "run.py b2t_custom_encoder finetuning",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_wav2vec_custom_encoder",
                "--batch_size=8",
                "--epochs=10",
                "--learning_rate=0.00001",
                "--unfreeze_strategy=all",
                "--sample_rate=50",
                "--tokenizer_checkpoint=facebook/wav2vec2-base-100h",
                "--wav2vec_checkpoint=facebook/wav2vec2-xls-r-300m",
                "--mode=finetuning",
                "--preprocessing=seperate_zscoring_2channels",
                "--loss_function=ctc",
                "--from_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2t_wav2vec_custom_encoder/2024-01-10_08#58#14/model.pt"
            ]
        },
        {
            "name": "run.py onehot_index",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=onehot_index",
                "--batch_size=1",
                "--epochs=1000",
                "--learning_rate=0.001",
                "--sample_rate=50",
                "--tokenizer_checkpoint=facebook/wav2vec2-base-100h",
                "--preprocessing=seperate_zscoring_2channels",
                "--loss_function=ctc",
                "--limit_samples=1",
                "--predict_on_train=true"
            ]
        },
        {
            "name": "run.py direct_cnn",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_cnn",
                "--batch_size=1",
                "--epochs=1000",
                "--learning_rate=0.1",
                "--sample_rate=50",
                "--tokenizer_checkpoint=facebook/wav2vec2-base-100h",
                "--preprocessing=seperate_zscoring_2channels",
                "--loss_function=ctc",
                "--limit_samples=1",
                "--predict_on_train=true",
                "--return_best_model=false"
            ]
        },
        {
            "name": "run.py 4_channel_cnn_wav2vec",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--experiment_type=b2t_wav2vec_resnet"
            ]
        },
        {
            "name": "run.py gru overfit",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_gru",
                "--batch_size=1",
                "--epochs=100",
                "--learning_rate=0.1",
                "--sample_rate=50",
                "--preprocessing=seperate_zscoring",
                "--loss_function=ctc",
                "--limit_samples=1",
                "--predict_on_train=true",
                "--return_best_model=false"
            ]
        },
        {
            "name": "run.py gru",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_gru",
                "--batch_size=8",
                "--epochs=10",
                "--learning_rate=0.001",
                "--sample_rate=50",
                "--preprocessing=seperate_zscoring",
                "--loss_function=ctc",
                "--predict_on_train=true",
                "--return_best_model=true",
                "--gradient_clipping=1"
            ]
        },
        {
            "name": "run.py gru trafo",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_gru+trafo",
                "--batch_size=64",
                "--epochs=30",
                "--learning_rate=0.01",
                "--dropout=0.3",
                "--sample_rate=50",
                "--preprocessing=seperate_zscoring",
                "--loss_function=ctc",
                "--predict_on_train=true",
                "--return_best_model=true",
                "--gradient_clipping=1",
                "--use_fast_tokenizer=True",
                "--language_model_mode=lm",
                "--training_task=trafo",
                "--from_checkpoint=/hpi/fs00/scratch/leon.hermann/b2t/cache/experiment_results/b2t_gru+trafo_experiment/2024-02-17_13#29#27/model.pt"
            ]
        },
        {
            "name": "run.py mamba only test good model",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2t_mamba",
                "--preprocessing=seperate_zscoring",
                "--batch_size=2",
                "--predict_on_train=True",
                "--n_layer=64",
                "--learning_rate=0.000015",
                "--return_best_model=true",
                "--epochs=100",
                "--d_model=256",
                "--rms_norm=true",
                "--feature_extractor_activation=sigmoid",
                "--scheduler_step_size=20",
                "--scheduler_gamma=0.9",
                "--from_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/best/2024-02-08_06#06#45/model.pt",
                "--input_dropout=0.5",
                "--only_test=true",
                "--visualize_predictions_n_batches=4",
                "--limit_samples=8",
                "--predict_on_train=false"
            ]
        },
        {
            "name": "run.py ctc lm overfit",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=ctc_lm",
                "--batch_size=1",
                "--limit_samples=1",
                "--epochs=100",
                "--learning_rate=0.0000001",
                "--scheduler_gamma=1",
                "--num_layers=32",
                "--classifier_hidden_sizes=[256]"
            ]
        },
        {
            "name": "run.py b2p2t_gru",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2p2t_gru",
                "--preprocessing=seperate_zscoring",
                "--batch_size=64",
                "--predict_on_train=True",
                "--learning_rate=0.02",
                "--return_best_model=true",
                "--epochs=64",
                "--scheduler_step_size=10",
                "--scheduler_gamma=1",
                "--dropout=0.4",
                "--weight_decay=1e-5",
                "--hidden_size=1024",
                "--num_gru_layers=5",
                "--whiteNoiseSD=0.8",
                "--constantOffsetSD=0.2",
                "--gaussian_smooth_width=2",
                "--unfolder_stride_len=4",
                "--unfolder_kernel_len=32",
                "--bidirectional=true"
            ]
        },
        {
            "name": "decoding/preprocess.py",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/decoding/postprocess.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${workspaceFolder}",
                "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION": "python"
            },
            "justMyCode": true,
            "args": [
                "--data_dir",
                "/hpi/fs00/home/tobias.fiedler/brain2text/temp/6d752d4e-cbf5-4355-be80-ca1f06b89df4"
            ]
        },
        {
            "name": "decoding/preprocess_baseline.py",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/decoding/postprocess_baseline.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${workspaceFolder}",
                "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION": "python"
            },
            "justMyCode": true,
            "args": [
                "--data_dir",
                "/hpi/fs00/home/tobias.fiedler/brain2text/temp/898a4cf5-c398-4499-895f-0f39b4a0d7f0"
            ]
        },
        {
            "name": "run.py b2p2t_gru limit_samples=64",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2p2t_gru",
                "--preprocessing=seperate_zscoring",
                "--batch_size=8",
                "--predict_on_train=True",
                "--learning_rate=0.02",
                "--return_best_model=true",
                "--epochs=64",
                "--scheduler_step_size=10",
                "--scheduler_gamma=1",
                "--dropout=0.4",
                "--weight_decay=1e-5",
                "--hidden_size=1024",
                "--num_gru_layers=5",
                "--whiteNoiseSD=0.8",
                "--constantOffsetSD=0.2",
                "--gaussian_smooth_width=2",
                "--unfolder_stride_len=4",
                "--unfolder_kernel_len=32",
                "--bidirectional=true",
                "--limit_samples=64"
            ]
        },
        { // STEP 1: train SUC on independant phoneme samples
            "name": "run.py suc timit",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=timit_w2v_suc"
            ]
        },
        { // STEP 2: train GRU head attached on SUC via CTC loss on audio
            "name": "b2p suc_for_ctc",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--learning_rate=0.0001",
                "--scheduler_gamma=0.32777878218184253",
                "--suc_dropout=0.4002714380900173",
                "--suc_hidden_sizes=[4096,1024,512,256]",
                "--weight_decay=4.412757798785471e-05",
                "--early_stopping_patience=4",
                "--experiment_type=timit_w2v_suc_ctc",
                "--return_best_model=true",
                "--epochs=40",
                "--batch_size=4",
                "--scheduler_step_size=8",
                "--optimizer_epsilon=0.1",
                "--gradient_clipping=1",
                "--ctc_gru_hidden_size=40",
                "--suc_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/timit_w2v_suc/2024-07-18_12#09#56/suc.pt",
                "--ctc_num_gru_layers=1"
            ]
        },
        {
            "name": "b2p suc_for_ctc + discriminator loss",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            //python run.py --experiment_type=b2p_suc --suc_for_ctc_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/timit_w2v_suc_ctc/2024-07-26_18#18#50/suc_for_ctc.pt --ctc_gru_hidden_size=120 --ctc_num_gru_layers=2 --learning_rate=0.01 --suc_hidden_sizes=[] --weight_decay=4.412757798785471e-05 --return_best_model=true --epochs=100 --batch_size=32 --scheduler_step_size=5 --optimizer_epsilon=0.1 --gradient_clipping=1 --scheduler_gamma=0.99 --loss_function=ctc --day_batches=false --use_wandb=true --encoder_dropout=0.4 --discriminator_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/discriminator/2024-07-30_09#39#34/discriminator.pt
            "args": [
                "--experiment_type=b2p_suc",
                "--suc_for_ctc_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/timit_w2v_suc_ctc/2024-07-26_18#18#50/suc_for_ctc.pt",
                "--ctc_gru_hidden_size=120",
                "--ctc_num_gru_layers=2",
                "--learning_rate=0.01",
                "--suc_hidden_sizes=[]",
                "--weight_decay=4.412757798785471e-05",
                "--return_best_model=true",
                "--epochs=100",
                "--batch_size=32",
                "--scheduler_step_size=5",
                "--optimizer_epsilon=0.1",
                "--gradient_clipping=1",
                "--scheduler_gamma=0.99",
                "--loss_function=ctc",
                "--day_batches=false",
                "--encoder_dropout=0.4",
                "--discriminator_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/discriminator/2024-07-30_09#39#34/discriminator.pt"
            ]
        },
        { // STEP 3: train brain data encoder using pretrained SUC and GRU head
            "name": "b2p brain_encoder with suc_for_ctc",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=b2p_suc",
                // "--suc_for_ctc_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/timit_w2v_suc_ctc/2024-07-26_18#18#50/suc_for_ctc.pt",
                "--ctc_gru_hidden_size=120",
                "--ctc_num_gru_layers=2",
                "--learning_rate=0.000963724197394264",
                "--suc_hidden_sizes=[]",
                "--weight_decay=4.412757798785471e-05",
                "--early_stopping_patience=4",
                "--return_best_model=true",
                "--epochs=200",
                "--batch_size=32",
                "--scheduler_step_size=5",
                "--optimizer_epsilon=0.1",
                "--gradient_clipping=1",
                "--scheduler_gamma=0.5",
                "--loss_function=ctc",
                "--limit_samples=32",
                "--day_batches=false",
                "--from_checkpoint=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2p_suc/2024-07-28_13#50#12/model.pt"
            ]
        },
        { // python run.py --experiment_type=b2p_suc --from_checkpoint="/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2p_suc/2024-07-29_07#16#02/model.pt" --encoder_gru_hidden_size=256 --encoder_fc_hidden_sizes=[] --encoder_num_gru_layers=2 --ctc_num_gru_layers=2 --ctc_gru_hidden_size=120 --only_test=true --predict_on_train=true
            "name": "discriminator",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--experiment_type=discriminator",
                "--brain_encoder_path=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2p_suc/2024-07-30_14#32#20/brain_encoder.pt",
                "--encoder_gru_hidden_size=256",
                "--encoder_fc_hidden_sizes=[]",
                "--encoder_num_gru_layers=2",
                "--ctc_num_gru_layers=2",
                "--ctc_gru_hidden_size=120"
            ]
        },
        {
            "name": "GRU+W2V",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/run.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            //python run.py --experiment_type="b2p2t_gru+w2v" --brain_encoder_path=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2p_suc/2024-07-30_14#32#20/brain_encoder.pt --encoder_gru_hidden_size=256 --encoder_fc_hidden_sizes=[] --encoder_num_gru_layers=2 --ctc_num_gru_layers=2 --ctc_gru_hidden_size=120 --epochs=1 --only_test=true
            "args": [
                "--experiment_type=b2p2t_gru+w2v",
                "--brain_encoder_path=/hpi/fs00/scratch/tobias.fiedler/brain2text/experiment_results/b2p_suc/2024-07-30_14#32#20/brain_encoder.pt",
                "--encoder_gru_hidden_size=256",
                "--encoder_fc_hidden_sizes=[]",
                "--encoder_num_gru_layers=2",
                "--ctc_num_gru_layers=2",
                "--ctc_gru_hidden_size=120",
                "--epochs=1",
                "--only_test=true"
            ]
        }
    ],
}